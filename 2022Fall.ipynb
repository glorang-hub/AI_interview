{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "꾸그 AI챕터 인터뷰 ver.2022Fall\n",
    "=====\n",
    "----\n",
    "\n",
    "안녕하세요! *너가 재밌으면 나도 재밌어!*  **꾸그**에 관심을 가지고 지원해주셔서 감사드립니다.\n",
    "서류 통과를 축하드리며, 면접 단계에서는 코드를 완성해오신 뒤 작성 내용에 관한 면접 및 NLP, 딥러닝, 머신러닝에 관한 면접을 수행하게 됩니다. 문제는 총 2가지이며, 추가 문제는 선택 사항입니다.\n",
    "\n",
    "* 논문 요약: 5개의 논문 중 하나를 선택해 요약하기\n",
    "* 프로그래밍 문제: Torch Implementation\n",
    "* (추가 점수) 이론 문제: Back to basic\n",
    "\n",
    "문제를 모두 다 풀지 않아도 면접은 진행되니 혹시 안 풀리더라도 너무 걱정마시고, 외부 검색을 통해 답을 찾아서 작성시 출처를 표기해주세요!\n",
    "\n",
    "------\n",
    "\n",
    "\n",
    "## 1. 논문 요약 과제\n",
    "======\n",
    "\n",
    "**아래 5개의 논문 중 하나를 선택하여 요약해주시면 됩니다(글자 수 제한: 750자).**\n",
    "\n",
    "* [Attention is all you need](https://arxiv.org/abs/1706.03762)\n",
    "* [BERT: Pre-trainig of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)\n",
    "* [BART - Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension](https://arxiv.org/abs/1910.13461)\n",
    "* [Improving Language Understanding by Generative Pre-Training](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf)\n",
    "* [RoBERTa: A Robustly Optimized BERT Pretraining Approach](https://arxiv.org/abs/1907.11692)\n",
    "\n",
    "이 중 하나를 선택해 아래의 3가지 질문을 위주로 답변을 하시면 됩니다.\n",
    "1. 이 논문이 참고한 문헌 중 하나를 선택해 간단히 설명해주세요.\n",
    "2. 이 논문은 해당 참고문헌으로부터 어떤 점을 발전시켰나요?\n",
    "3. 어떤 점을 추가로 더 발전시킬 수 있을까요?\n",
    "\n",
    "\n",
    "답변은 아래의 코드 셀에다가 해주시면 됩니다. 총 답변의 길이는 750자를 넘으면 안 됩니다.(권장 글자수: 500자 혹은 그 이상)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 우측의 목록에서 논문을 선택해주세요.\n",
    "title = 'Attention is all you need' #@param [\"Attention is All you need\", \"BERT: Pre-trainig of Deep Bidirectional Transformers for Language Understanding\", \"BART - Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension\", \"Improving Language Understanding by Generative Pre-Training\", \"RoBERTa: A Robustly Optimized BERT Pretraining Approach\"]\n",
    "\n",
    "# 여기에 답변을 작성해주세요.\n",
    "summary = \"\"\"\n",
    "\n",
    "TODO\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# 작성을 마치신 뒤 셀을 실행해주시면 총 글자수가 출력됩니다.\n",
    "import re\n",
    "pattern = re.compile(r'\\s+')\n",
    "length = len(re.sub(pattern, '', summary))\n",
    "\n",
    "print(\"논문명: {}\".format(title))\n",
    "print(\"답변 길이: {}자\".format(length))\n",
    "assert length <= 750, \"답변의 길이가 750자를 넘었습니다\"\n",
    "print(summary)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "------\n",
    "## 2. 프로그래밍 문제\n",
    "문제를 풀기전에 먼저 아래의 코드 셀을 실행해주세요."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "path = \"data.pkl\"\n",
    "with open(path, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "data, label = load_data()\n",
    "print(data.shape, label.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### PyTorch implementation 문제1\n",
    "\n",
    "주어진 data의 각 sample은 1 또는 -1을 원소로 갖는 n-dim binary vector(np.array)와 one-hot vector로 표현된 label로 이루어져 있습니다.\n",
    "(n = 12)\n",
    "\n",
    "XOR 연산을 일반화할 수 있는 여러 문제들 중 하나는 홀/짝 문제입니다.\n",
    "**$n$개의 원소를 갖는 1차원 bool 벡터의 $L_0-norm$의 값이 홀/짝인지 판단하는 문제**에서, $n=2$일 때, XOR 연산과 동일합니다.\n",
    "(여기서 $L_0-norm$은 벡터 내에 0이 아닌 원소의 갯수를 의미합니다.)\n",
    "\n",
    "**PyTorch를 이용하여 주어진 data에 대해 위 문제의 답을 출력하는 머신을 지도학습 기반으로 학습시켜주세요.**\n",
    "\n",
    "단, 여기에선 $2^n$개의 samples, $U$를 전부 이용하여 학습시키지 않고 그 중 일부만을 사용하여야 합니다.\n",
    "**train, test, validation sets를 본인의 기준에 맞게 나누고 그렇게 나눈 이유를 정성적으로 설명해주세요.**\n",
    "\n",
    "\n",
    "$2^n$개의 samples를 갖고있는 dataset $U$를 가정합니다.\n",
    "( i.e. $|U|$ = #($U$) = $2^n$ *such that* #(train) + #(test) + #(validation) = $2^n$ and\n",
    "train $\\cup$ test $\\cup$ validation = $U$ )\n",
    "\n",
    "\n",
    "**참고자료**\n",
    "* [XOR_gate | wikipedia](https://en.wikipedia.org/wiki/XOR_gate)\n",
    "* [Lp-norm | wikipedia](https://en.wikipedia.org/wiki/Lp_space#When_p_=_0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# TODO\n",
    "train_data_x =\n",
    "test_data_x =\n",
    "validation_data_x =\n",
    "\n",
    "train_data_y =\n",
    "test_data_y =\n",
    "validation_data_y =\n",
    "\n",
    "train_data_x = torch.tensor(train_data_x, dtype=torch.float64, device=device).double()\n",
    "train_data_y = torch.tensor(train_data_y, dtype=torch.float64, device=device).double()\n",
    "test_data_x = torch.tensor(test_data_x, dtype=torch.float64, device=device).double()\n",
    "test_data_y = torch.tensor(test_data_y, dtype=torch.float64, device=device).double()\n",
    "validation_data_x = torch.tensor(validation_data_x, dtype=torch.float64, device=device).double()\n",
    "validation_data_y = torch.tensor(validation_data_y, dtype=torch.float64, device=device).double()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "dataset = TensorDataset(train_data_x, train_data_y)\n",
    "# TODO\n",
    "dataloader = DataLoader(dataset, batch_size=, shuffle=)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        # TODO\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### PyTorch implementation 문제2\n",
    "\n",
    "2차원 bool 벡터에 대해 CNN(Convolutional Neural Network) 구조를 이용하여 동일한 과정을 시행해주세요."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_data_x = train_data_x.view(-1, 1, 4, 3)\n",
    "test_data_x = test_data_x.view(-1, 1, 4, 3)\n",
    "validation_data_x = validation_data_x.view(-1, 1, 4, 3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset = TensorDataset(train_data_x, train_data_y)\n",
    "# TODO\n",
    "dataloader = DataLoader(dataset, batch_size=, shuffle=)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channel, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        # TODO\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## (추가 문제) 이론 문제\n",
    "### Back to basic\n",
    "\n",
    "XOR연산은 AND 나 OR 연산과 달리 single perceptron만으로는 풀 수 없습니다.\n",
    "\n",
    "이는 decision boudary가 linear하게 정해질 수 없기 때문인데요, DNN이 필요한 간단한 예시로 자주 사용되곤 합니다.\n",
    "\n",
    "c/c++ 혹은 python의 기본 함수들(STL, numpy 등 사용 가능)을 이용하여 다음 XOR 연산을 수행하는 머신을 지도학습 기반으로 만들어주세요.\n",
    "\n",
    "autograd 기능이 없는 libarary라면 필요에 따라 사용하셔도 됩니다.\n",
    "\n",
    "** XOR **\n",
    "\n",
    "| $input_1$ | $input_2$ |  $output$  |\n",
    "| :---: | :---: | :---: |\n",
    "| 0     | 0     | 0     |\n",
    "| 0     | 1     | 1     |\n",
    "| 1     | 0     | 1     |\n",
    "| 1     | 1     | 0     |\n",
    "\n",
    "문제를 푸는 데 도움이 될만한 링크를 아래 남겨두었습니다.\n",
    "\n",
    "**참고자료**\n",
    "* [XOR_gate | wikipedia](https://en.wikipedia.org/wiki/XOR_gate)\n",
    "* [Speech and Language Processing, Ch.7 | Daniel Jurafsky & James H. Martin](https://web.stanford.edu/~jurafsky/slp3/7.pdf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO\n",
    "# In this stage, you are allowed to take the training phase only, since there are only four samples."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 제출 방법\n",
    "\n",
    "작성을 완료하신 이후에는 이 IPython notebook을 .ipynb 형식으로 저장 후 __benny@glorang.com__ 으로 보내주세요!\n",
    "\n",
    "수고하셨습니다!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}